{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CBCYekt99VTk"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import time\n",
    "from PIL import Image\n",
    "import datetime\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.models import Sequential, Model, load_model, model_from_json\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Input, Convolution2D, ZeroPadding2D, AveragePooling2D, GlobalAveragePooling2D, MaxPooling2D, Flatten, Dropout, Activation, Reshape\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.utils import to_categorical  \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix, classification_report, multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "uMehMDI3eVja"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Train: 2054\n",
      "X Test: 1074\n",
      "Y Train: 2054\n",
      "Y Test: 1074\n"
     ]
    }
   ],
   "source": [
    "#/global/scratch/users/cpezov/AAPBO/images/BenchmarkX/file_name.png\n",
    "#/global/scratch/users/cpezov/AAPBO/labels.txt\n",
    "\n",
    "x_train_all = []\n",
    "y_train_all = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "main_path=\"/global/scratch/users/cpezov/AAPBO/\"\n",
    "d_path = main_path + \"datasets-v4/\"\n",
    "i_path = main_path + \"images/\"\n",
    "\n",
    "num_class=8 #7 solvers and \"No solution\"   #v4\n",
    "\n",
    "#Get each one of the images, in order\n",
    "#Randomly assign to test/train set, per family\n",
    "random.seed(9)\n",
    "with open(d_path+\"txt_files/data_ordered.txt\") as f:\n",
    "    lines = f.readlines()\n",
    "    for l in lines:\n",
    "        r = random.randint(0,2)\n",
    "        end = l.rfind(\".\")\n",
    "        img_name = i_path + l[2:end] + \".png\"\n",
    "        #print(img_name)\n",
    "        file_name = d_path + l[2:]\n",
    "        #print(file_name)\n",
    "        if(r==2):\n",
    "            x_test.append(img_to_array(load_img(img_name,color_mode=\"grayscale\")))\n",
    "        else:\n",
    "            x_train_all.append(img_to_array(load_img(img_name,color_mode=\"grayscale\")))\n",
    "        \n",
    "print(\"X Train: \"+str(len(x_train_all)))\n",
    "print(\"X Test: \"+str(len(x_test)))\n",
    "\n",
    "#read labels and transform to one-hot\n",
    "random.seed(9) #same seed to generate same random numbers as before \n",
    "with open(main_path+\"labels-v4.txt\") as f: #v4\n",
    "    lines = f.readlines()\n",
    "    for l in lines:\n",
    "        r = random.randint(0,2)\n",
    "        lbls = [int(x) for x in l.split()]\n",
    "        one_hot = to_categorical(lbls, num_classes=num_class)\n",
    "        if(r==2):\n",
    "            y_test.append(one_hot)\n",
    "        else:\n",
    "            y_train_all.append(one_hot)\n",
    "            \n",
    "print(\"Y Train: \"+str(len(y_train_all)))\n",
    "print(\"Y Test: \"+str(len(y_test)))\n",
    "            \n",
    "#x_train, x_test, y_train, y_test = model_selection.train_test_split (x, y, test_size=1./3.)\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1645, 256, 256, 1)\n",
      "(1645, 500, 8)\n",
      "(409, 256, 256, 1)\n",
      "(409, 500, 8)\n"
     ]
    }
   ],
   "source": [
    "#Once separated train/test, the train set must be separated train/validation in 80:20 (4:1) ratio\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_val = []\n",
    "y_val = []\n",
    "\n",
    "random.seed(3)\n",
    "for i in range(len(y_train_all)):\n",
    "    r = random.randint(0,4)\n",
    "    if(r==4):\n",
    "        x_val.append(x_train_all[i])\n",
    "        y_val.append(y_train_all[i])\n",
    "    else:\n",
    "        x_train.append(x_train_all[i])\n",
    "        y_train.append(y_train_all[i])\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_val = np.array(x_val)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 62, 62, 96)        11712     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 62, 96)        384       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 30, 30, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 256)       614656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 30, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 384)       885120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 14, 14, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 256)       884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              37752832  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4000)              16388000  \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 500, 8)            0         \n",
      "=================================================================\n",
      "Total params: 74,651,616\n",
      "Trainable params: 74,648,864\n",
      "Non-trainable params: 2,752\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 3.8738 - acc: 0.1230 - mse: 0.1249WARNING:tensorflow:From /global/software/sl-7.x86_64/modules/apps/ml/tensorflow/2.3.0-py37/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      " 2/13 [===>..........................] - ETA: 1s - loss: 3.2375 - acc: 0.1434 - mse: 0.1249WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1174s vs `on_train_batch_end` time: 0.2412s). Check your callbacks.\n",
      "13/13 [==============================] - ETA: 0s - loss: 2.1365 - acc: 0.2872 - mse: 0.1249\n",
      "Epoch 00001: val_acc improved from -inf to 0.43430, saving model to /global/scratch/users/cpezov/AAPBO/models/v4/alexNet-v4/models/model.h5\n",
      "13/13 [==============================] - 13s 1s/step - loss: 2.1365 - acc: 0.2872 - mse: 0.1249 - val_loss: 1.7622 - val_acc: 0.4343 - val_mse: 0.1249\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.6860 - acc: 0.4432 - mse: 0.1249\n",
      "Epoch 00002: val_acc improved from 0.43430 to 0.45910, saving model to /global/scratch/users/cpezov/AAPBO/models/v4/alexNet-v4/models/model.h5\n",
      "13/13 [==============================] - 10s 796ms/step - loss: 1.6860 - acc: 0.4432 - mse: 0.1249 - val_loss: 1.7665 - val_acc: 0.4591 - val_mse: 0.1249\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.5808 - acc: 0.4644 - mse: 0.1248\n",
      "Epoch 00003: val_acc improved from 0.45910 to 0.46269, saving model to /global/scratch/users/cpezov/AAPBO/models/v4/alexNet-v4/models/model.h5\n",
      "13/13 [==============================] - 10s 794ms/step - loss: 1.5808 - acc: 0.4644 - mse: 0.1248 - val_loss: 1.8071 - val_acc: 0.4627 - val_mse: 0.1249\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.5178 - acc: 0.4715 - mse: 0.1248\n",
      "Epoch 00004: val_acc did not improve from 0.46269\n",
      "13/13 [==============================] - 8s 645ms/step - loss: 1.5178 - acc: 0.4715 - mse: 0.1248 - val_loss: 1.7670 - val_acc: 0.4602 - val_mse: 0.1249\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.4379 - acc: 0.4790 - mse: 0.1248\n",
      "Epoch 00005: val_acc did not improve from 0.46269\n",
      "13/13 [==============================] - 8s 642ms/step - loss: 1.4379 - acc: 0.4790 - mse: 0.1248 - val_loss: 1.7560 - val_acc: 0.4181 - val_mse: 0.1249\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.3643 - acc: 0.4907 - mse: 0.1248\n",
      "Epoch 00006: val_acc did not improve from 0.46269\n",
      "13/13 [==============================] - 8s 642ms/step - loss: 1.3643 - acc: 0.4907 - mse: 0.1248 - val_loss: 2.1214 - val_acc: 0.1491 - val_mse: 0.1249\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.2961 - acc: 0.5063 - mse: 0.1248\n",
      "Epoch 00007: val_acc did not improve from 0.46269\n",
      "13/13 [==============================] - 8s 645ms/step - loss: 1.2961 - acc: 0.5063 - mse: 0.1248 - val_loss: 2.2150 - val_acc: 0.1198 - val_mse: 0.1249\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.2285 - acc: 0.5229 - mse: 0.1248\n",
      "Epoch 00008: val_acc did not improve from 0.46269\n",
      "13/13 [==============================] - 8s 643ms/step - loss: 1.2285 - acc: 0.5229 - mse: 0.1248 - val_loss: 2.1652 - val_acc: 0.1172 - val_mse: 0.1249\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.1547 - acc: 0.5493 - mse: 0.1248\n",
      "Epoch 00009: val_acc did not improve from 0.46269\n",
      "13/13 [==============================] - 8s 645ms/step - loss: 1.1547 - acc: 0.5493 - mse: 0.1248 - val_loss: 2.1809 - val_acc: 0.1188 - val_mse: 0.1249\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.0717 - acc: 0.5918 - mse: 0.1247\n",
      "Epoch 00010: val_acc did not improve from 0.46269\n",
      "13/13 [==============================] - 8s 642ms/step - loss: 1.0717 - acc: 0.5918 - mse: 0.1247 - val_loss: 2.4785 - val_acc: 0.1263 - val_mse: 0.1249\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.0057 - acc: 0.6250 - mse: 0.1247\n",
      "Epoch 00011: val_acc did not improve from 0.46269\n",
      "13/13 [==============================] - 8s 643ms/step - loss: 1.0057 - acc: 0.6250 - mse: 0.1247 - val_loss: 2.0139 - val_acc: 0.1889 - val_mse: 0.1249\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.9576 - acc: 0.6445 - mse: 0.1247\n",
      "Epoch 00012: val_acc did not improve from 0.46269\n",
      "13/13 [==============================] - 8s 640ms/step - loss: 0.9576 - acc: 0.6445 - mse: 0.1247 - val_loss: 1.9384 - val_acc: 0.3168 - val_mse: 0.1249\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.8894 - acc: 0.6733 - mse: 0.1247\n",
      "Epoch 00013: val_acc did not improve from 0.46269\n",
      "13/13 [==============================] - 8s 645ms/step - loss: 0.8894 - acc: 0.6733 - mse: 0.1247 - val_loss: 2.5658 - val_acc: 0.4612 - val_mse: 0.1248\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.8571 - acc: 0.6816 - mse: 0.1247\n",
      "Epoch 00014: val_acc improved from 0.46269 to 0.46781, saving model to /global/scratch/users/cpezov/AAPBO/models/v4/alexNet-v4/models/model.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 11s 808ms/step - loss: 0.8571 - acc: 0.6816 - mse: 0.1247 - val_loss: 2.7736 - val_acc: 0.4678 - val_mse: 0.1248\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.8274 - acc: 0.6878 - mse: 0.1247\n",
      "Epoch 00015: val_acc did not improve from 0.46781\n",
      "13/13 [==============================] - 8s 641ms/step - loss: 0.8274 - acc: 0.6878 - mse: 0.1247 - val_loss: 2.3366 - val_acc: 0.4636 - val_mse: 0.1248\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.7817 - acc: 0.7028 - mse: 0.1247\n",
      "Epoch 00016: val_acc did not improve from 0.46781\n",
      "13/13 [==============================] - 8s 644ms/step - loss: 0.7817 - acc: 0.7028 - mse: 0.1247 - val_loss: 3.2228 - val_acc: 0.4660 - val_mse: 0.1248\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.7637 - acc: 0.7105 - mse: 0.1247\n",
      "Epoch 00017: val_acc did not improve from 0.46781\n",
      "13/13 [==============================] - 8s 645ms/step - loss: 0.7637 - acc: 0.7105 - mse: 0.1247 - val_loss: 2.8456 - val_acc: 0.4291 - val_mse: 0.1248\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.7226 - acc: 0.7300 - mse: 0.1247\n",
      "Epoch 00018: val_acc did not improve from 0.46781\n",
      "13/13 [==============================] - 8s 644ms/step - loss: 0.7226 - acc: 0.7300 - mse: 0.1247 - val_loss: 4.0606 - val_acc: 0.4670 - val_mse: 0.1248\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.6939 - acc: 0.7456 - mse: 0.1246\n",
      "Epoch 00019: val_acc did not improve from 0.46781\n",
      "13/13 [==============================] - 8s 642ms/step - loss: 0.6939 - acc: 0.7456 - mse: 0.1246 - val_loss: 3.3210 - val_acc: 0.3960 - val_mse: 0.1248\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.6601 - acc: 0.7617 - mse: 0.1246\n",
      "Epoch 00020: val_acc did not improve from 0.46781\n",
      "13/13 [==============================] - 8s 646ms/step - loss: 0.6601 - acc: 0.7617 - mse: 0.1246 - val_loss: 2.4691 - val_acc: 0.3659 - val_mse: 0.1248\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.6166 - acc: 0.7881 - mse: 0.1246\n",
      "Epoch 00021: val_acc did not improve from 0.46781\n",
      "13/13 [==============================] - 8s 645ms/step - loss: 0.6166 - acc: 0.7881 - mse: 0.1246 - val_loss: 1.8392 - val_acc: 0.4634 - val_mse: 0.1248\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.5997 - acc: 0.7940 - mse: 0.1246\n",
      "Epoch 00022: val_acc improved from 0.46781 to 0.47994, saving model to /global/scratch/users/cpezov/AAPBO/models/v4/alexNet-v4/models/model.h5\n",
      "13/13 [==============================] - 10s 787ms/step - loss: 0.5997 - acc: 0.7940 - mse: 0.1246 - val_loss: 5.2481 - val_acc: 0.4799 - val_mse: 0.1247\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.5631 - acc: 0.8048 - mse: 0.1246\n",
      "Epoch 00023: val_acc improved from 0.47994 to 0.48626, saving model to /global/scratch/users/cpezov/AAPBO/models/v4/alexNet-v4/models/model.h5\n",
      "13/13 [==============================] - 11s 810ms/step - loss: 0.5631 - acc: 0.8048 - mse: 0.1246 - val_loss: 2.7564 - val_acc: 0.4863 - val_mse: 0.1248\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.5255 - acc: 0.8238 - mse: 0.1246\n",
      "Epoch 00024: val_acc did not improve from 0.48626\n",
      "13/13 [==============================] - 8s 636ms/step - loss: 0.5255 - acc: 0.8238 - mse: 0.1246 - val_loss: 2.7393 - val_acc: 0.4780 - val_mse: 0.1248\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.5009 - acc: 0.8298 - mse: 0.1246\n",
      "Epoch 00025: val_acc did not improve from 0.48626\n",
      "13/13 [==============================] - 8s 639ms/step - loss: 0.5009 - acc: 0.8298 - mse: 0.1246 - val_loss: 1.7350 - val_acc: 0.4768 - val_mse: 0.1248\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.4850 - acc: 0.8379 - mse: 0.1246\n",
      "Epoch 00026: val_acc improved from 0.48626 to 0.49532, saving model to /global/scratch/users/cpezov/AAPBO/models/v4/alexNet-v4/models/model.h5\n",
      "13/13 [==============================] - 10s 800ms/step - loss: 0.4850 - acc: 0.8379 - mse: 0.1246 - val_loss: 2.6887 - val_acc: 0.4953 - val_mse: 0.1248\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.4578 - acc: 0.8440 - mse: 0.1246\n",
      "Epoch 00027: val_acc did not improve from 0.49532\n",
      "13/13 [==============================] - 8s 639ms/step - loss: 0.4578 - acc: 0.8440 - mse: 0.1246 - val_loss: 2.7185 - val_acc: 0.3322 - val_mse: 0.1248\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.4384 - acc: 0.8510 - mse: 0.1246\n",
      "Epoch 00028: val_acc improved from 0.49532 to 0.50883, saving model to /global/scratch/users/cpezov/AAPBO/models/v4/alexNet-v4/models/model.h5\n",
      "13/13 [==============================] - 10s 804ms/step - loss: 0.4384 - acc: 0.8510 - mse: 0.1246 - val_loss: 3.1374 - val_acc: 0.5088 - val_mse: 0.1247\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.4132 - acc: 0.8571 - mse: 0.1246\n",
      "Epoch 00029: val_acc did not improve from 0.50883\n",
      "13/13 [==============================] - 8s 634ms/step - loss: 0.4132 - acc: 0.8571 - mse: 0.1246 - val_loss: 3.2380 - val_acc: 0.3686 - val_mse: 0.1248\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.4016 - acc: 0.8597 - mse: 0.1246\n",
      "Epoch 00030: val_acc did not improve from 0.50883\n",
      "13/13 [==============================] - 8s 641ms/step - loss: 0.4016 - acc: 0.8597 - mse: 0.1246 - val_loss: 2.4344 - val_acc: 0.4878 - val_mse: 0.1248\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.4021 - acc: 0.8579 - mse: 0.1246\n",
      "Epoch 00031: val_acc did not improve from 0.50883\n",
      "13/13 [==============================] - 8s 639ms/step - loss: 0.4021 - acc: 0.8579 - mse: 0.1246 - val_loss: 1.7055 - val_acc: 0.4394 - val_mse: 0.1248\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.3831 - acc: 0.8667 - mse: 0.1246\n",
      "Epoch 00032: val_acc improved from 0.50883 to 0.51974, saving model to /global/scratch/users/cpezov/AAPBO/models/v4/alexNet-v4/models/model.h5\n",
      "13/13 [==============================] - 10s 805ms/step - loss: 0.3831 - acc: 0.8667 - mse: 0.1246 - val_loss: 1.8327 - val_acc: 0.5197 - val_mse: 0.1248\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.3935 - acc: 0.8619 - mse: 0.1246\n",
      "Epoch 00033: val_acc improved from 0.51974 to 0.52370, saving model to /global/scratch/users/cpezov/AAPBO/models/v4/alexNet-v4/models/model.h5\n",
      "13/13 [==============================] - 10s 802ms/step - loss: 0.3935 - acc: 0.8619 - mse: 0.1246 - val_loss: 2.4402 - val_acc: 0.5237 - val_mse: 0.1247\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.3737 - acc: 0.8736 - mse: 0.1246\n",
      "Epoch 00034: val_acc improved from 0.52370 to 0.52712, saving model to /global/scratch/users/cpezov/AAPBO/models/v4/alexNet-v4/models/model.h5\n",
      "13/13 [==============================] - 10s 805ms/step - loss: 0.3737 - acc: 0.8736 - mse: 0.1246 - val_loss: 3.0468 - val_acc: 0.5271 - val_mse: 0.1247\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.3606 - acc: 0.8746 - mse: 0.1246\n",
      "Epoch 00035: val_acc improved from 0.52712 to 0.52747, saving model to /global/scratch/users/cpezov/AAPBO/models/v4/alexNet-v4/models/model.h5\n",
      "13/13 [==============================] - 10s 805ms/step - loss: 0.3606 - acc: 0.8746 - mse: 0.1246 - val_loss: 1.7922 - val_acc: 0.5275 - val_mse: 0.1248\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.3456 - acc: 0.8852 - mse: 0.1246\n",
      "Epoch 00036: val_acc improved from 0.52747 to 0.53071, saving model to /global/scratch/users/cpezov/AAPBO/models/v4/alexNet-v4/models/model.h5\n",
      "13/13 [==============================] - 10s 799ms/step - loss: 0.3456 - acc: 0.8852 - mse: 0.1246 - val_loss: 1.9383 - val_acc: 0.5307 - val_mse: 0.1248\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.3394 - acc: 0.8823 - mse: 0.1246\n",
      "Epoch 00037: val_acc did not improve from 0.53071\n",
      "13/13 [==============================] - 8s 642ms/step - loss: 0.3394 - acc: 0.8823 - mse: 0.1246 - val_loss: 2.3946 - val_acc: 0.5121 - val_mse: 0.1247\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.3343 - acc: 0.8848 - mse: 0.1246\n",
      "Epoch 00038: val_acc did not improve from 0.53071\n",
      "13/13 [==============================] - 8s 643ms/step - loss: 0.3343 - acc: 0.8848 - mse: 0.1246 - val_loss: 1.9155 - val_acc: 0.4666 - val_mse: 0.1248\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.3276 - acc: 0.8915 - mse: 0.1246\n",
      "Epoch 00039: val_acc did not improve from 0.53071\n",
      "13/13 [==============================] - 8s 642ms/step - loss: 0.3276 - acc: 0.8915 - mse: 0.1246 - val_loss: 1.7720 - val_acc: 0.4507 - val_mse: 0.1248\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.3122 - acc: 0.8924 - mse: 0.1246\n",
      "Epoch 00040: val_acc did not improve from 0.53071\n",
      "13/13 [==============================] - 8s 642ms/step - loss: 0.3122 - acc: 0.8924 - mse: 0.1246 - val_loss: 2.9285 - val_acc: 0.3647 - val_mse: 0.1248\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.3114 - acc: 0.8927 - mse: 0.1246\n",
      "Epoch 00041: val_acc improved from 0.53071 to 0.53743, saving model to /global/scratch/users/cpezov/AAPBO/models/v4/alexNet-v4/models/model.h5\n",
      "13/13 [==============================] - 10s 804ms/step - loss: 0.3114 - acc: 0.8927 - mse: 0.1246 - val_loss: 2.0426 - val_acc: 0.5374 - val_mse: 0.1248\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.3053 - acc: 0.8944 - mse: 0.1246\n",
      "Epoch 00042: val_acc did not improve from 0.53743\n",
      "13/13 [==============================] - 8s 646ms/step - loss: 0.3053 - acc: 0.8944 - mse: 0.1246 - val_loss: 1.7654 - val_acc: 0.4819 - val_mse: 0.1248\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2982 - acc: 0.8929 - mse: 0.1246\n",
      "Epoch 00043: val_acc did not improve from 0.53743\n",
      "13/13 [==============================] - 8s 644ms/step - loss: 0.2982 - acc: 0.8929 - mse: 0.1246 - val_loss: 1.9437 - val_acc: 0.5128 - val_mse: 0.1248\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.3000 - acc: 0.8946 - mse: 0.1246\n",
      "Epoch 00044: val_acc did not improve from 0.53743\n",
      "13/13 [==============================] - 8s 640ms/step - loss: 0.3000 - acc: 0.8946 - mse: 0.1246 - val_loss: 2.9841 - val_acc: 0.5264 - val_mse: 0.1247\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2927 - acc: 0.8946 - mse: 0.1246\n",
      "Epoch 00045: val_acc did not improve from 0.53743\n",
      "13/13 [==============================] - 8s 636ms/step - loss: 0.2927 - acc: 0.8946 - mse: 0.1246 - val_loss: 3.2832 - val_acc: 0.5012 - val_mse: 0.1247\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2845 - acc: 0.8992 - mse: 0.1246\n",
      "Epoch 00046: val_acc improved from 0.53743 to 0.53961, saving model to /global/scratch/users/cpezov/AAPBO/models/v4/alexNet-v4/models/model.h5\n",
      "13/13 [==============================] - 10s 804ms/step - loss: 0.2845 - acc: 0.8992 - mse: 0.1246 - val_loss: 2.0143 - val_acc: 0.5396 - val_mse: 0.1247\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2808 - acc: 0.8991 - mse: 0.1246\n",
      "Epoch 00047: val_acc improved from 0.53961 to 0.54090, saving model to /global/scratch/users/cpezov/AAPBO/models/v4/alexNet-v4/models/model.h5\n",
      "13/13 [==============================] - 11s 813ms/step - loss: 0.2808 - acc: 0.8991 - mse: 0.1246 - val_loss: 1.9358 - val_acc: 0.5409 - val_mse: 0.1247\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2739 - acc: 0.9017 - mse: 0.1246\n",
      "Epoch 00048: val_acc did not improve from 0.54090\n",
      "13/13 [==============================] - 8s 638ms/step - loss: 0.2739 - acc: 0.9017 - mse: 0.1246 - val_loss: 2.2863 - val_acc: 0.5409 - val_mse: 0.1247\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2721 - acc: 0.9006 - mse: 0.1246\n",
      "Epoch 00049: val_acc did not improve from 0.54090\n",
      "13/13 [==============================] - 8s 638ms/step - loss: 0.2721 - acc: 0.9006 - mse: 0.1246 - val_loss: 2.0765 - val_acc: 0.4559 - val_mse: 0.1248\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2699 - acc: 0.9017 - mse: 0.1246\n",
      "Epoch 00050: val_acc did not improve from 0.54090\n",
      "13/13 [==============================] - 8s 638ms/step - loss: 0.2699 - acc: 0.9017 - mse: 0.1246 - val_loss: 1.8582 - val_acc: 0.4898 - val_mse: 0.1248\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2605 - acc: 0.9038 - mse: 0.1246\n",
      "Epoch 00051: val_acc did not improve from 0.54090\n",
      "13/13 [==============================] - 8s 638ms/step - loss: 0.2605 - acc: 0.9038 - mse: 0.1246 - val_loss: 1.6735 - val_acc: 0.4927 - val_mse: 0.1248\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2586 - acc: 0.9044 - mse: 0.1246\n",
      "Epoch 00052: val_acc did not improve from 0.54090\n",
      "13/13 [==============================] - 8s 645ms/step - loss: 0.2586 - acc: 0.9044 - mse: 0.1246 - val_loss: 1.7243 - val_acc: 0.5055 - val_mse: 0.1248\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2557 - acc: 0.9067 - mse: 0.1246\n",
      "Epoch 00053: val_acc improved from 0.54090 to 0.54674, saving model to /global/scratch/users/cpezov/AAPBO/models/v4/alexNet-v4/models/model.h5\n",
      "13/13 [==============================] - 10s 806ms/step - loss: 0.2557 - acc: 0.9067 - mse: 0.1246 - val_loss: 2.4162 - val_acc: 0.5467 - val_mse: 0.1247\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2595 - acc: 0.9078 - mse: 0.1246\n",
      "Epoch 00054: val_acc did not improve from 0.54674\n",
      "13/13 [==============================] - 8s 643ms/step - loss: 0.2595 - acc: 0.9078 - mse: 0.1246 - val_loss: 1.7485 - val_acc: 0.5014 - val_mse: 0.1248\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2528 - acc: 0.9077 - mse: 0.1246\n",
      "Epoch 00055: val_acc did not improve from 0.54674\n",
      "13/13 [==============================] - 8s 637ms/step - loss: 0.2528 - acc: 0.9077 - mse: 0.1246 - val_loss: 1.8156 - val_acc: 0.5156 - val_mse: 0.1248\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2440 - acc: 0.9088 - mse: 0.1246\n",
      "Epoch 00056: val_acc did not improve from 0.54674\n",
      "13/13 [==============================] - 8s 636ms/step - loss: 0.2440 - acc: 0.9088 - mse: 0.1246 - val_loss: 1.9065 - val_acc: 0.5389 - val_mse: 0.1247\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2498 - acc: 0.9082 - mse: 0.1246\n",
      "Epoch 00057: val_acc did not improve from 0.54674\n",
      "13/13 [==============================] - 8s 644ms/step - loss: 0.2498 - acc: 0.9082 - mse: 0.1246 - val_loss: 1.9093 - val_acc: 0.5003 - val_mse: 0.1248\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2480 - acc: 0.9075 - mse: 0.1246\n",
      "Epoch 00058: val_acc did not improve from 0.54674\n",
      "13/13 [==============================] - 8s 645ms/step - loss: 0.2480 - acc: 0.9075 - mse: 0.1246 - val_loss: 2.2557 - val_acc: 0.4457 - val_mse: 0.1248\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2447 - acc: 0.9115 - mse: 0.1246\n",
      "Epoch 00059: val_acc did not improve from 0.54674\n",
      "13/13 [==============================] - 8s 642ms/step - loss: 0.2447 - acc: 0.9115 - mse: 0.1246 - val_loss: 1.9148 - val_acc: 0.4759 - val_mse: 0.1248\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2406 - acc: 0.9118 - mse: 0.1246\n",
      "Epoch 00060: val_acc did not improve from 0.54674\n",
      "13/13 [==============================] - 8s 644ms/step - loss: 0.2406 - acc: 0.9118 - mse: 0.1246 - val_loss: 2.0373 - val_acc: 0.5451 - val_mse: 0.1247\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2328 - acc: 0.9126 - mse: 0.1245\n",
      "Epoch 00061: val_acc did not improve from 0.54674\n",
      "13/13 [==============================] - 8s 643ms/step - loss: 0.2328 - acc: 0.9126 - mse: 0.1245 - val_loss: 1.8455 - val_acc: 0.5033 - val_mse: 0.1248\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2311 - acc: 0.9161 - mse: 0.1245\n",
      "Epoch 00062: val_acc did not improve from 0.54674\n",
      "13/13 [==============================] - 8s 644ms/step - loss: 0.2311 - acc: 0.9161 - mse: 0.1245 - val_loss: 1.9090 - val_acc: 0.5324 - val_mse: 0.1247\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2296 - acc: 0.9139 - mse: 0.1245\n",
      "Epoch 00063: val_acc did not improve from 0.54674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 8s 644ms/step - loss: 0.2296 - acc: 0.9139 - mse: 0.1245 - val_loss: 1.9989 - val_acc: 0.5150 - val_mse: 0.1248\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2237 - acc: 0.9167 - mse: 0.1245\n",
      "Epoch 00064: val_acc did not improve from 0.54674\n",
      "13/13 [==============================] - 8s 643ms/step - loss: 0.2237 - acc: 0.9167 - mse: 0.1245 - val_loss: 2.2628 - val_acc: 0.5007 - val_mse: 0.1248\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2217 - acc: 0.9174 - mse: 0.1245\n",
      "Epoch 00065: val_acc did not improve from 0.54674\n",
      "13/13 [==============================] - 8s 641ms/step - loss: 0.2217 - acc: 0.9174 - mse: 0.1245 - val_loss: 4.2791 - val_acc: 0.4220 - val_mse: 0.1248\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2238 - acc: 0.9179 - mse: 0.1245\n",
      "Epoch 00066: val_acc did not improve from 0.54674\n",
      "13/13 [==============================] - 8s 644ms/step - loss: 0.2238 - acc: 0.9179 - mse: 0.1245 - val_loss: 3.1492 - val_acc: 0.5418 - val_mse: 0.1247\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2138 - acc: 0.9207 - mse: 0.1245\n",
      "Epoch 00067: val_acc did not improve from 0.54674\n",
      "13/13 [==============================] - 8s 638ms/step - loss: 0.2138 - acc: 0.9207 - mse: 0.1245 - val_loss: 4.8450 - val_acc: 0.5169 - val_mse: 0.1247\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2170 - acc: 0.9188 - mse: 0.1245\n",
      "Epoch 00068: val_acc did not improve from 0.54674\n",
      "13/13 [==============================] - 8s 644ms/step - loss: 0.2170 - acc: 0.9188 - mse: 0.1245 - val_loss: 2.2812 - val_acc: 0.5428 - val_mse: 0.1247\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2112 - acc: 0.9204 - mse: 0.1245\n",
      "Epoch 00069: val_acc did not improve from 0.54674\n",
      "13/13 [==============================] - 8s 639ms/step - loss: 0.2112 - acc: 0.9204 - mse: 0.1245 - val_loss: 2.6662 - val_acc: 0.5408 - val_mse: 0.1247\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2080 - acc: 0.9237 - mse: 0.1245\n",
      "Epoch 00070: val_acc did not improve from 0.54674\n",
      "13/13 [==============================] - 8s 647ms/step - loss: 0.2080 - acc: 0.9237 - mse: 0.1245 - val_loss: 2.6781 - val_acc: 0.5302 - val_mse: 0.1247\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2059 - acc: 0.9233 - mse: 0.1245\n",
      "Epoch 00071: val_acc did not improve from 0.54674\n",
      "13/13 [==============================] - 8s 638ms/step - loss: 0.2059 - acc: 0.9233 - mse: 0.1245 - val_loss: 3.4631 - val_acc: 0.4719 - val_mse: 0.1248\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2104 - acc: 0.9219 - mse: 0.1245\n",
      "Epoch 00072: val_acc did not improve from 0.54674\n",
      "13/13 [==============================] - 8s 646ms/step - loss: 0.2104 - acc: 0.9219 - mse: 0.1245 - val_loss: 2.1182 - val_acc: 0.4831 - val_mse: 0.1248\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2080 - acc: 0.9219 - mse: 0.1245\n",
      "Epoch 00073: val_acc did not improve from 0.54674\n",
      "13/13 [==============================] - 8s 641ms/step - loss: 0.2080 - acc: 0.9219 - mse: 0.1245 - val_loss: 2.3438 - val_acc: 0.4131 - val_mse: 0.1248\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2087 - acc: 0.9224 - mse: 0.1245\n",
      "Epoch 00074: val_acc did not improve from 0.54674\n",
      "13/13 [==============================] - 8s 642ms/step - loss: 0.2087 - acc: 0.9224 - mse: 0.1245 - val_loss: 2.8786 - val_acc: 0.4146 - val_mse: 0.1248\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2006 - acc: 0.9249 - mse: 0.1245\n",
      "Epoch 00075: val_acc did not improve from 0.54674\n",
      "13/13 [==============================] - 8s 645ms/step - loss: 0.2006 - acc: 0.9249 - mse: 0.1245 - val_loss: 2.9504 - val_acc: 0.4072 - val_mse: 0.1248\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1965 - acc: 0.9242 - mse: 0.1245\n",
      "Epoch 00076: val_acc did not improve from 0.54674\n",
      "13/13 [==============================] - 8s 650ms/step - loss: 0.1965 - acc: 0.9242 - mse: 0.1245 - val_loss: 2.4379 - val_acc: 0.5327 - val_mse: 0.1247\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1946 - acc: 0.9260 - mse: 0.1245\n",
      "Epoch 00077: val_acc did not improve from 0.54674\n",
      "13/13 [==============================] - 8s 644ms/step - loss: 0.1946 - acc: 0.9260 - mse: 0.1245 - val_loss: 1.9099 - val_acc: 0.5176 - val_mse: 0.1248\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2039 - acc: 0.9249 - mse: 0.1245\n",
      "Epoch 00078: val_acc did not improve from 0.54674\n",
      "13/13 [==============================] - 8s 644ms/step - loss: 0.2039 - acc: 0.9249 - mse: 0.1245 - val_loss: 3.1321 - val_acc: 0.5408 - val_mse: 0.1247\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1915 - acc: 0.9279 - mse: 0.1245\n",
      "Epoch 00079: val_acc improved from 0.54674 to 0.55543, saving model to /global/scratch/users/cpezov/AAPBO/models/v4/alexNet-v4/models/model.h5\n",
      "13/13 [==============================] - 10s 788ms/step - loss: 0.1915 - acc: 0.9279 - mse: 0.1245 - val_loss: 2.9581 - val_acc: 0.5554 - val_mse: 0.1247\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1885 - acc: 0.9293 - mse: 0.1245\n",
      "Epoch 00080: val_acc did not improve from 0.55543\n",
      "13/13 [==============================] - 8s 639ms/step - loss: 0.1885 - acc: 0.9293 - mse: 0.1245 - val_loss: 2.5660 - val_acc: 0.5323 - val_mse: 0.1247\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1876 - acc: 0.9286 - mse: 0.1245\n",
      "Epoch 00081: val_acc did not improve from 0.55543\n",
      "13/13 [==============================] - 8s 643ms/step - loss: 0.1876 - acc: 0.9286 - mse: 0.1245 - val_loss: 2.2341 - val_acc: 0.5197 - val_mse: 0.1248\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1880 - acc: 0.9291 - mse: 0.1245\n",
      "Epoch 00082: val_acc did not improve from 0.55543\n",
      "13/13 [==============================] - 8s 644ms/step - loss: 0.1880 - acc: 0.9291 - mse: 0.1245 - val_loss: 2.5024 - val_acc: 0.5461 - val_mse: 0.1247\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1896 - acc: 0.9281 - mse: 0.1245\n",
      "Epoch 00083: val_acc improved from 0.55543 to 0.55690, saving model to /global/scratch/users/cpezov/AAPBO/models/v4/alexNet-v4/models/model.h5\n",
      "13/13 [==============================] - 10s 800ms/step - loss: 0.1896 - acc: 0.9281 - mse: 0.1245 - val_loss: 2.3475 - val_acc: 0.5569 - val_mse: 0.1247\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1890 - acc: 0.9281 - mse: 0.1245\n",
      "Epoch 00084: val_acc did not improve from 0.55690\n",
      "13/13 [==============================] - 8s 639ms/step - loss: 0.1890 - acc: 0.9281 - mse: 0.1245 - val_loss: 3.1118 - val_acc: 0.5482 - val_mse: 0.1247\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1898 - acc: 0.9280 - mse: 0.1245\n",
      "Epoch 00085: val_acc did not improve from 0.55690\n",
      "13/13 [==============================] - 8s 637ms/step - loss: 0.1898 - acc: 0.9280 - mse: 0.1245 - val_loss: 1.9160 - val_acc: 0.5500 - val_mse: 0.1247\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1828 - acc: 0.9319 - mse: 0.1245\n",
      "Epoch 00086: val_acc did not improve from 0.55690\n",
      "13/13 [==============================] - 8s 647ms/step - loss: 0.1828 - acc: 0.9319 - mse: 0.1245 - val_loss: 2.2188 - val_acc: 0.5369 - val_mse: 0.1247\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1817 - acc: 0.9303 - mse: 0.1245\n",
      "Epoch 00087: val_acc did not improve from 0.55690\n",
      "13/13 [==============================] - 8s 637ms/step - loss: 0.1817 - acc: 0.9303 - mse: 0.1245 - val_loss: 1.9876 - val_acc: 0.5174 - val_mse: 0.1248\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1779 - acc: 0.9311 - mse: 0.1245\n",
      "Epoch 00088: val_acc did not improve from 0.55690\n",
      "13/13 [==============================] - 8s 640ms/step - loss: 0.1779 - acc: 0.9311 - mse: 0.1245 - val_loss: 2.3077 - val_acc: 0.4842 - val_mse: 0.1248\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1798 - acc: 0.9328 - mse: 0.1245\n",
      "Epoch 00089: val_acc did not improve from 0.55690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 8s 644ms/step - loss: 0.1798 - acc: 0.9328 - mse: 0.1245 - val_loss: 2.4723 - val_acc: 0.5025 - val_mse: 0.1248\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1773 - acc: 0.9321 - mse: 0.1245\n",
      "Epoch 00090: val_acc did not improve from 0.55690\n",
      "13/13 [==============================] - 8s 645ms/step - loss: 0.1773 - acc: 0.9321 - mse: 0.1245 - val_loss: 2.2348 - val_acc: 0.5236 - val_mse: 0.1248\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1770 - acc: 0.9330 - mse: 0.1245\n",
      "Epoch 00091: val_acc did not improve from 0.55690\n",
      "13/13 [==============================] - 8s 639ms/step - loss: 0.1770 - acc: 0.9330 - mse: 0.1245 - val_loss: 3.3908 - val_acc: 0.5463 - val_mse: 0.1247\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1710 - acc: 0.9332 - mse: 0.1245\n",
      "Epoch 00092: val_acc did not improve from 0.55690\n",
      "13/13 [==============================] - 8s 646ms/step - loss: 0.1710 - acc: 0.9332 - mse: 0.1245 - val_loss: 2.1618 - val_acc: 0.5010 - val_mse: 0.1248\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1679 - acc: 0.9351 - mse: 0.1245\n",
      "Epoch 00093: val_acc did not improve from 0.55690\n",
      "13/13 [==============================] - 8s 644ms/step - loss: 0.1679 - acc: 0.9351 - mse: 0.1245 - val_loss: 2.7894 - val_acc: 0.5476 - val_mse: 0.1247\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1651 - acc: 0.9356 - mse: 0.1245\n",
      "Epoch 00094: val_acc did not improve from 0.55690\n",
      "13/13 [==============================] - 8s 643ms/step - loss: 0.1651 - acc: 0.9356 - mse: 0.1245 - val_loss: 2.8198 - val_acc: 0.5516 - val_mse: 0.1247\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1720 - acc: 0.9349 - mse: 0.1245\n",
      "Epoch 00095: val_acc did not improve from 0.55690\n",
      "13/13 [==============================] - 8s 640ms/step - loss: 0.1720 - acc: 0.9349 - mse: 0.1245 - val_loss: 2.3047 - val_acc: 0.5245 - val_mse: 0.1248\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1626 - acc: 0.9363 - mse: 0.1245\n",
      "Epoch 00096: val_acc did not improve from 0.55690\n",
      "13/13 [==============================] - 8s 640ms/step - loss: 0.1626 - acc: 0.9363 - mse: 0.1245 - val_loss: 3.3790 - val_acc: 0.4231 - val_mse: 0.1248\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1619 - acc: 0.9378 - mse: 0.1245\n",
      "Epoch 00097: val_acc did not improve from 0.55690\n",
      "13/13 [==============================] - 8s 640ms/step - loss: 0.1619 - acc: 0.9378 - mse: 0.1245 - val_loss: 3.5142 - val_acc: 0.5073 - val_mse: 0.1248\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1665 - acc: 0.9341 - mse: 0.1245\n",
      "Epoch 00098: val_acc did not improve from 0.55690\n",
      "13/13 [==============================] - 8s 642ms/step - loss: 0.1665 - acc: 0.9341 - mse: 0.1245 - val_loss: 2.3417 - val_acc: 0.5334 - val_mse: 0.1248\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1610 - acc: 0.9371 - mse: 0.1245\n",
      "Epoch 00099: val_acc did not improve from 0.55690\n",
      "13/13 [==============================] - 8s 643ms/step - loss: 0.1610 - acc: 0.9371 - mse: 0.1245 - val_loss: 2.9590 - val_acc: 0.5256 - val_mse: 0.1247\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1674 - acc: 0.9370 - mse: 0.1245\n",
      "Epoch 00100: val_acc did not improve from 0.55690\n",
      "13/13 [==============================] - 8s 643ms/step - loss: 0.1674 - acc: 0.9370 - mse: 0.1245 - val_loss: 2.0535 - val_acc: 0.4772 - val_mse: 0.1248\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1632 - acc: 0.9372 - mse: 0.1245\n",
      "Epoch 00101: val_acc did not improve from 0.55690\n",
      "13/13 [==============================] - 8s 647ms/step - loss: 0.1632 - acc: 0.9372 - mse: 0.1245 - val_loss: 2.0938 - val_acc: 0.4640 - val_mse: 0.1248\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1633 - acc: 0.9374 - mse: 0.1245\n",
      "Epoch 00102: val_acc did not improve from 0.55690\n",
      "13/13 [==============================] - 8s 641ms/step - loss: 0.1633 - acc: 0.9374 - mse: 0.1245 - val_loss: 4.0074 - val_acc: 0.4450 - val_mse: 0.1248\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1556 - acc: 0.9398 - mse: 0.1245\n",
      "Epoch 00103: val_acc did not improve from 0.55690\n",
      "13/13 [==============================] - 8s 643ms/step - loss: 0.1556 - acc: 0.9398 - mse: 0.1245 - val_loss: 3.7930 - val_acc: 0.4734 - val_mse: 0.1248\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1627 - acc: 0.9386 - mse: 0.1245\n",
      "Epoch 00104: val_acc did not improve from 0.55690\n",
      "13/13 [==============================] - 8s 649ms/step - loss: 0.1627 - acc: 0.9386 - mse: 0.1245 - val_loss: 3.0853 - val_acc: 0.4841 - val_mse: 0.1248\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1543 - acc: 0.9407 - mse: 0.1245\n",
      "Epoch 00105: val_acc did not improve from 0.55690\n",
      "13/13 [==============================] - 8s 638ms/step - loss: 0.1543 - acc: 0.9407 - mse: 0.1245 - val_loss: 2.8435 - val_acc: 0.4970 - val_mse: 0.1248\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1494 - acc: 0.9409 - mse: 0.1245\n",
      "Epoch 00106: val_acc did not improve from 0.55690\n",
      "13/13 [==============================] - 8s 639ms/step - loss: 0.1494 - acc: 0.9409 - mse: 0.1245 - val_loss: 3.0220 - val_acc: 0.5401 - val_mse: 0.1247\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1503 - acc: 0.9397 - mse: 0.1245\n",
      "Epoch 00107: val_acc did not improve from 0.55690\n",
      "13/13 [==============================] - 8s 642ms/step - loss: 0.1503 - acc: 0.9397 - mse: 0.1245 - val_loss: 3.2028 - val_acc: 0.4462 - val_mse: 0.1248\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1522 - acc: 0.9426 - mse: 0.1245\n",
      "Epoch 00108: val_acc did not improve from 0.55690\n",
      "13/13 [==============================] - 8s 636ms/step - loss: 0.1522 - acc: 0.9426 - mse: 0.1245 - val_loss: 2.0617 - val_acc: 0.5243 - val_mse: 0.1248\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1481 - acc: 0.9429 - mse: 0.1245\n",
      "Epoch 00109: val_acc did not improve from 0.55690\n",
      "13/13 [==============================] - 8s 641ms/step - loss: 0.1481 - acc: 0.9429 - mse: 0.1245 - val_loss: 2.2740 - val_acc: 0.5388 - val_mse: 0.1247\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1473 - acc: 0.9419 - mse: 0.1245\n",
      "Epoch 00110: val_acc did not improve from 0.55690\n",
      "13/13 [==============================] - 8s 647ms/step - loss: 0.1473 - acc: 0.9419 - mse: 0.1245 - val_loss: 1.9566 - val_acc: 0.5447 - val_mse: 0.1248\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1574 - acc: 0.9401 - mse: 0.1245\n",
      "Epoch 00111: val_acc did not improve from 0.55690\n",
      "13/13 [==============================] - 8s 644ms/step - loss: 0.1574 - acc: 0.9401 - mse: 0.1245 - val_loss: 1.9770 - val_acc: 0.5384 - val_mse: 0.1247\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1625 - acc: 0.9408 - mse: 0.1245\n",
      "Epoch 00112: val_acc did not improve from 0.55690\n",
      "13/13 [==============================] - 8s 643ms/step - loss: 0.1625 - acc: 0.9408 - mse: 0.1245 - val_loss: 2.0418 - val_acc: 0.5126 - val_mse: 0.1248\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1569 - acc: 0.9392 - mse: 0.1245\n",
      "Epoch 00113: val_acc did not improve from 0.55690\n",
      "13/13 [==============================] - 8s 637ms/step - loss: 0.1569 - acc: 0.9392 - mse: 0.1245 - val_loss: 2.5352 - val_acc: 0.5499 - val_mse: 0.1247\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1545 - acc: 0.9395 - mse: 0.1245\n",
      "Epoch 00114: val_acc did not improve from 0.55690\n",
      "13/13 [==============================] - 8s 639ms/step - loss: 0.1545 - acc: 0.9395 - mse: 0.1245 - val_loss: 3.4378 - val_acc: 0.5398 - val_mse: 0.1247\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1522 - acc: 0.9406 - mse: 0.1245\n",
      "Epoch 00115: val_acc did not improve from 0.55690\n",
      "13/13 [==============================] - 8s 643ms/step - loss: 0.1522 - acc: 0.9406 - mse: 0.1245 - val_loss: 2.2887 - val_acc: 0.5357 - val_mse: 0.1247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1476 - acc: 0.9410 - mse: 0.1245\n",
      "Epoch 00116: val_acc did not improve from 0.55690\n",
      "13/13 [==============================] - 8s 644ms/step - loss: 0.1476 - acc: 0.9410 - mse: 0.1245 - val_loss: 2.2668 - val_acc: 0.5532 - val_mse: 0.1247\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1476 - acc: 0.9429 - mse: 0.1245\n",
      "Epoch 00117: val_acc did not improve from 0.55690\n",
      "13/13 [==============================] - 8s 646ms/step - loss: 0.1476 - acc: 0.9429 - mse: 0.1245 - val_loss: 1.8166 - val_acc: 0.5134 - val_mse: 0.1248\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1595 - acc: 0.9392 - mse: 0.1245\n",
      "Epoch 00118: val_acc did not improve from 0.55690\n",
      "13/13 [==============================] - 8s 643ms/step - loss: 0.1595 - acc: 0.9392 - mse: 0.1245 - val_loss: 2.4337 - val_acc: 0.5205 - val_mse: 0.1248\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1447 - acc: 0.9438 - mse: 0.1245\n",
      "Epoch 00119: val_acc did not improve from 0.55690\n",
      "13/13 [==============================] - 8s 642ms/step - loss: 0.1447 - acc: 0.9438 - mse: 0.1245 - val_loss: 3.6371 - val_acc: 0.5330 - val_mse: 0.1247\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1464 - acc: 0.9430 - mse: 0.1245\n",
      "Epoch 00120: val_acc did not improve from 0.55690\n",
      "13/13 [==============================] - 8s 638ms/step - loss: 0.1464 - acc: 0.9430 - mse: 0.1245 - val_loss: 2.6594 - val_acc: 0.5176 - val_mse: 0.1248\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1500 - acc: 0.9424 - mse: 0.1245\n",
      "Epoch 00121: val_acc did not improve from 0.55690\n",
      "13/13 [==============================] - 8s 641ms/step - loss: 0.1500 - acc: 0.9424 - mse: 0.1245 - val_loss: 2.3353 - val_acc: 0.5548 - val_mse: 0.1247\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1402 - acc: 0.9443 - mse: 0.1245\n",
      "Epoch 00122: val_acc did not improve from 0.55690\n",
      "13/13 [==============================] - 8s 646ms/step - loss: 0.1402 - acc: 0.9443 - mse: 0.1245 - val_loss: 2.5284 - val_acc: 0.5122 - val_mse: 0.1248\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1467 - acc: 0.9434 - mse: 0.1245\n",
      "Epoch 00123: val_acc did not improve from 0.55690\n",
      "13/13 [==============================] - 8s 642ms/step - loss: 0.1467 - acc: 0.9434 - mse: 0.1245 - val_loss: 2.6184 - val_acc: 0.5316 - val_mse: 0.1247\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1383 - acc: 0.9458 - mse: 0.1245\n",
      "Epoch 00124: val_acc did not improve from 0.55690\n",
      "13/13 [==============================] - 8s 648ms/step - loss: 0.1383 - acc: 0.9458 - mse: 0.1245 - val_loss: 2.9383 - val_acc: 0.5491 - val_mse: 0.1247\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1441 - acc: 0.9455 - mse: 0.1245\n",
      "Epoch 00125: val_acc did not improve from 0.55690\n",
      "13/13 [==============================] - 8s 645ms/step - loss: 0.1441 - acc: 0.9455 - mse: 0.1245 - val_loss: 3.2293 - val_acc: 0.5411 - val_mse: 0.1247\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1403 - acc: 0.9461 - mse: 0.1245\n",
      "Epoch 00126: val_acc improved from 0.55690 to 0.56084, saving model to /global/scratch/users/cpezov/AAPBO/models/v4/alexNet-v4/models/model.h5\n",
      "13/13 [==============================] - 10s 804ms/step - loss: 0.1403 - acc: 0.9461 - mse: 0.1245 - val_loss: 2.9884 - val_acc: 0.5608 - val_mse: 0.1247\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1407 - acc: 0.9452 - mse: 0.1245\n",
      "Epoch 00127: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 647ms/step - loss: 0.1407 - acc: 0.9452 - mse: 0.1245 - val_loss: 3.0738 - val_acc: 0.5518 - val_mse: 0.1247\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1395 - acc: 0.9470 - mse: 0.1245\n",
      "Epoch 00128: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 638ms/step - loss: 0.1395 - acc: 0.9470 - mse: 0.1245 - val_loss: 2.3277 - val_acc: 0.5235 - val_mse: 0.1248\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1395 - acc: 0.9434 - mse: 0.1245\n",
      "Epoch 00129: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 641ms/step - loss: 0.1395 - acc: 0.9434 - mse: 0.1245 - val_loss: 3.1110 - val_acc: 0.4505 - val_mse: 0.1248\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1383 - acc: 0.9475 - mse: 0.1245\n",
      "Epoch 00130: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 648ms/step - loss: 0.1383 - acc: 0.9475 - mse: 0.1245 - val_loss: 2.9718 - val_acc: 0.5491 - val_mse: 0.1247\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1308 - acc: 0.9477 - mse: 0.1245\n",
      "Epoch 00131: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 640ms/step - loss: 0.1308 - acc: 0.9477 - mse: 0.1245 - val_loss: 2.7829 - val_acc: 0.5528 - val_mse: 0.1247\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1425 - acc: 0.9442 - mse: 0.1245\n",
      "Epoch 00132: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 645ms/step - loss: 0.1425 - acc: 0.9442 - mse: 0.1245 - val_loss: 2.4097 - val_acc: 0.5359 - val_mse: 0.1247\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1362 - acc: 0.9465 - mse: 0.1245\n",
      "Epoch 00133: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 641ms/step - loss: 0.1362 - acc: 0.9465 - mse: 0.1245 - val_loss: 2.3375 - val_acc: 0.5371 - val_mse: 0.1247\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1392 - acc: 0.9456 - mse: 0.1245\n",
      "Epoch 00134: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 639ms/step - loss: 0.1392 - acc: 0.9456 - mse: 0.1245 - val_loss: 2.6504 - val_acc: 0.5427 - val_mse: 0.1247\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1336 - acc: 0.9475 - mse: 0.1245\n",
      "Epoch 00135: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 642ms/step - loss: 0.1336 - acc: 0.9475 - mse: 0.1245 - val_loss: 2.5697 - val_acc: 0.5469 - val_mse: 0.1247\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1324 - acc: 0.9492 - mse: 0.1245\n",
      "Epoch 00136: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 643ms/step - loss: 0.1324 - acc: 0.9492 - mse: 0.1245 - val_loss: 2.2058 - val_acc: 0.5408 - val_mse: 0.1247\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1332 - acc: 0.9468 - mse: 0.1245\n",
      "Epoch 00137: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 643ms/step - loss: 0.1332 - acc: 0.9468 - mse: 0.1245 - val_loss: 2.2702 - val_acc: 0.5343 - val_mse: 0.1247\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1301 - acc: 0.9492 - mse: 0.1245\n",
      "Epoch 00138: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 638ms/step - loss: 0.1301 - acc: 0.9492 - mse: 0.1245 - val_loss: 2.4484 - val_acc: 0.5370 - val_mse: 0.1247\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1250 - acc: 0.9484 - mse: 0.1245\n",
      "Epoch 00139: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 643ms/step - loss: 0.1250 - acc: 0.9484 - mse: 0.1245 - val_loss: 3.3294 - val_acc: 0.5437 - val_mse: 0.1247\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1282 - acc: 0.9489 - mse: 0.1245\n",
      "Epoch 00140: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 639ms/step - loss: 0.1282 - acc: 0.9489 - mse: 0.1245 - val_loss: 2.5586 - val_acc: 0.5125 - val_mse: 0.1248\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1301 - acc: 0.9496 - mse: 0.1245\n",
      "Epoch 00141: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 641ms/step - loss: 0.1301 - acc: 0.9496 - mse: 0.1245 - val_loss: 3.1725 - val_acc: 0.4344 - val_mse: 0.1248\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1316 - acc: 0.9482 - mse: 0.1245\n",
      "Epoch 00142: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 647ms/step - loss: 0.1316 - acc: 0.9482 - mse: 0.1245 - val_loss: 3.6540 - val_acc: 0.4610 - val_mse: 0.1248\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1280 - acc: 0.9484 - mse: 0.1245\n",
      "Epoch 00143: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 641ms/step - loss: 0.1280 - acc: 0.9484 - mse: 0.1245 - val_loss: 3.0140 - val_acc: 0.5221 - val_mse: 0.1247\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1308 - acc: 0.9497 - mse: 0.1245\n",
      "Epoch 00144: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 642ms/step - loss: 0.1308 - acc: 0.9497 - mse: 0.1245 - val_loss: 2.8823 - val_acc: 0.4977 - val_mse: 0.1248\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1247 - acc: 0.9500 - mse: 0.1245\n",
      "Epoch 00145: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 649ms/step - loss: 0.1247 - acc: 0.9500 - mse: 0.1245 - val_loss: 2.4870 - val_acc: 0.5140 - val_mse: 0.1248\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1318 - acc: 0.9494 - mse: 0.1245\n",
      "Epoch 00146: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 642ms/step - loss: 0.1318 - acc: 0.9494 - mse: 0.1245 - val_loss: 2.7193 - val_acc: 0.5344 - val_mse: 0.1247\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1251 - acc: 0.9522 - mse: 0.1245\n",
      "Epoch 00147: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 638ms/step - loss: 0.1251 - acc: 0.9522 - mse: 0.1245 - val_loss: 2.3408 - val_acc: 0.4650 - val_mse: 0.1248\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1294 - acc: 0.9480 - mse: 0.1245\n",
      "Epoch 00148: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 639ms/step - loss: 0.1294 - acc: 0.9480 - mse: 0.1245 - val_loss: 2.2236 - val_acc: 0.5015 - val_mse: 0.1248\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1296 - acc: 0.9499 - mse: 0.1245\n",
      "Epoch 00149: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 644ms/step - loss: 0.1296 - acc: 0.9499 - mse: 0.1245 - val_loss: 3.9542 - val_acc: 0.3647 - val_mse: 0.1248\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1301 - acc: 0.9493 - mse: 0.1245\n",
      "Epoch 00150: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 644ms/step - loss: 0.1301 - acc: 0.9493 - mse: 0.1245 - val_loss: 4.4597 - val_acc: 0.4219 - val_mse: 0.1248\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1276 - acc: 0.9509 - mse: 0.1245\n",
      "Epoch 00151: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 647ms/step - loss: 0.1276 - acc: 0.9509 - mse: 0.1245 - val_loss: 3.2707 - val_acc: 0.5496 - val_mse: 0.1247\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1432 - acc: 0.9455 - mse: 0.1245\n",
      "Epoch 00152: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 639ms/step - loss: 0.1432 - acc: 0.9455 - mse: 0.1245 - val_loss: 3.5438 - val_acc: 0.2726 - val_mse: 0.1249\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1629 - acc: 0.9379 - mse: 0.1245\n",
      "Epoch 00153: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 642ms/step - loss: 0.1629 - acc: 0.9379 - mse: 0.1245 - val_loss: 4.9695 - val_acc: 0.4968 - val_mse: 0.1247\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1838 - acc: 0.9328 - mse: 0.1245\n",
      "Epoch 00154: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 641ms/step - loss: 0.1838 - acc: 0.9328 - mse: 0.1245 - val_loss: 3.8912 - val_acc: 0.1766 - val_mse: 0.1249\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1743 - acc: 0.9350 - mse: 0.1245\n",
      "Epoch 00155: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 644ms/step - loss: 0.1743 - acc: 0.9350 - mse: 0.1245 - val_loss: 2.5200 - val_acc: 0.5097 - val_mse: 0.1247\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1931 - acc: 0.9296 - mse: 0.1245\n",
      "Epoch 00156: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 646ms/step - loss: 0.1931 - acc: 0.9296 - mse: 0.1245 - val_loss: 3.6251 - val_acc: 0.3060 - val_mse: 0.1248\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2003 - acc: 0.9278 - mse: 0.1245\n",
      "Epoch 00157: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 643ms/step - loss: 0.2003 - acc: 0.9278 - mse: 0.1245 - val_loss: 4.3363 - val_acc: 0.4975 - val_mse: 0.1247\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1704 - acc: 0.9358 - mse: 0.1245\n",
      "Epoch 00158: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 643ms/step - loss: 0.1704 - acc: 0.9358 - mse: 0.1245 - val_loss: 6.2965 - val_acc: 0.4939 - val_mse: 0.1248\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1672 - acc: 0.9395 - mse: 0.1245\n",
      "Epoch 00159: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 646ms/step - loss: 0.1672 - acc: 0.9395 - mse: 0.1245 - val_loss: 3.0071 - val_acc: 0.5133 - val_mse: 0.1248\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1574 - acc: 0.9392 - mse: 0.1245\n",
      "Epoch 00160: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 646ms/step - loss: 0.1574 - acc: 0.9392 - mse: 0.1245 - val_loss: 3.9319 - val_acc: 0.4120 - val_mse: 0.1248\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1435 - acc: 0.9443 - mse: 0.1245\n",
      "Epoch 00161: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 638ms/step - loss: 0.1435 - acc: 0.9443 - mse: 0.1245 - val_loss: 4.3922 - val_acc: 0.5008 - val_mse: 0.1248\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1435 - acc: 0.9446 - mse: 0.1245\n",
      "Epoch 00162: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 639ms/step - loss: 0.1435 - acc: 0.9446 - mse: 0.1245 - val_loss: 3.7108 - val_acc: 0.4790 - val_mse: 0.1248\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1348 - acc: 0.9479 - mse: 0.1245\n",
      "Epoch 00163: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 9s 658ms/step - loss: 0.1348 - acc: 0.9479 - mse: 0.1245 - val_loss: 3.5715 - val_acc: 0.5161 - val_mse: 0.1247\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1316 - acc: 0.9491 - mse: 0.1245\n",
      "Epoch 00164: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 640ms/step - loss: 0.1316 - acc: 0.9491 - mse: 0.1245 - val_loss: 4.2270 - val_acc: 0.5132 - val_mse: 0.1247\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1306 - acc: 0.9484 - mse: 0.1245\n",
      "Epoch 00165: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 645ms/step - loss: 0.1306 - acc: 0.9484 - mse: 0.1245 - val_loss: 2.0563 - val_acc: 0.5151 - val_mse: 0.1248\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1264 - acc: 0.9507 - mse: 0.1245\n",
      "Epoch 00166: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 643ms/step - loss: 0.1264 - acc: 0.9507 - mse: 0.1245 - val_loss: 2.2842 - val_acc: 0.4342 - val_mse: 0.1248\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1288 - acc: 0.9517 - mse: 0.1245\n",
      "Epoch 00167: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 640ms/step - loss: 0.1288 - acc: 0.9517 - mse: 0.1245 - val_loss: 2.7862 - val_acc: 0.5366 - val_mse: 0.1247\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1264 - acc: 0.9503 - mse: 0.1245\n",
      "Epoch 00168: val_acc did not improve from 0.56084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 8s 645ms/step - loss: 0.1264 - acc: 0.9503 - mse: 0.1245 - val_loss: 3.5873 - val_acc: 0.5355 - val_mse: 0.1247\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1221 - acc: 0.9533 - mse: 0.1245\n",
      "Epoch 00169: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 646ms/step - loss: 0.1221 - acc: 0.9533 - mse: 0.1245 - val_loss: 2.9366 - val_acc: 0.5094 - val_mse: 0.1247\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1254 - acc: 0.9502 - mse: 0.1245\n",
      "Epoch 00170: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 646ms/step - loss: 0.1254 - acc: 0.9502 - mse: 0.1245 - val_loss: 2.3826 - val_acc: 0.5406 - val_mse: 0.1247\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1191 - acc: 0.9535 - mse: 0.1245\n",
      "Epoch 00171: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 646ms/step - loss: 0.1191 - acc: 0.9535 - mse: 0.1245 - val_loss: 1.9095 - val_acc: 0.5140 - val_mse: 0.1248\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1282 - acc: 0.9504 - mse: 0.1245\n",
      "Epoch 00172: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 639ms/step - loss: 0.1282 - acc: 0.9504 - mse: 0.1245 - val_loss: 1.9309 - val_acc: 0.4642 - val_mse: 0.1248\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1286 - acc: 0.9498 - mse: 0.1245\n",
      "Epoch 00173: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 645ms/step - loss: 0.1286 - acc: 0.9498 - mse: 0.1245 - val_loss: 1.9703 - val_acc: 0.4791 - val_mse: 0.1248\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1178 - acc: 0.9529 - mse: 0.1245\n",
      "Epoch 00174: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 646ms/step - loss: 0.1178 - acc: 0.9529 - mse: 0.1245 - val_loss: 2.2102 - val_acc: 0.5147 - val_mse: 0.1248\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1206 - acc: 0.9524 - mse: 0.1245\n",
      "Epoch 00175: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 643ms/step - loss: 0.1206 - acc: 0.9524 - mse: 0.1245 - val_loss: 2.1820 - val_acc: 0.5215 - val_mse: 0.1248\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1174 - acc: 0.9532 - mse: 0.1245\n",
      "Epoch 00176: val_acc did not improve from 0.56084\n",
      "13/13 [==============================] - 8s 644ms/step - loss: 0.1174 - acc: 0.9532 - mse: 0.1245 - val_loss: 2.3582 - val_acc: 0.5362 - val_mse: 0.1247\n",
      "Epoch 00176: early stopping\n"
     ]
    }
   ],
   "source": [
    "#Modelo\n",
    "\n",
    "input_shape = (256,256,1) #resolucion imagen orignal\n",
    "loss=\"categorical_crossentropy\"\n",
    "opt = keras.optimizers.Adam(learning_rate = 0.0001,epsilon=1e-08)\n",
    "#opt = SGD(lr=0.01)\n",
    "\n",
    "\n",
    "#ALEXNET\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=input_shape),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(4096, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(4096, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(500*num_class, activation='softmax'),\n",
    "    keras.layers.Reshape((500,num_class))\n",
    "])\n",
    "\n",
    "model.compile(loss=loss, optimizer=opt, metrics=['acc', 'mse'])      \n",
    "model.summary() #ver resumen red\n",
    "\n",
    "# regularizadores\n",
    "log_dir = main_path+\"models/v4/alexNet-v4/logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tb = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "mc = ModelCheckpoint(main_path+'models/v4/alexNet-v4/models/model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "es = EarlyStopping(monitor='val_acc',mode='max',patience=50, verbose=1)\n",
    "\n",
    "# fit model\n",
    "#posiblemente cambiar cant de epochs\n",
    "alexNet_HISTORY = model.fit(x=x_train, y=y_train, batch_size=128, epochs=1000, validation_data=(x_val,y_val), shuffle=True, verbose = 1,callbacks=[es,mc,tb])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n",
      " 1/34 [..............................] - ETA: 0sWARNING:tensorflow:Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0052s vs `on_predict_batch_end` time: 0.0280s). Check your callbacks.\n",
      "34/34 [==============================] - 1s 39ms/step\n"
     ]
    }
   ],
   "source": [
    "#Save info\n",
    "model_json = model.to_json()\n",
    "with open(main_path+\"models/v4/alexNet-v4/models/model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(main_path+\"models/v4/alexNet-v4/models/model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "f = open(main_path+\"models/v4/alexNet-v4/results/y_test.txt\", \"w\")\n",
    "np.savetxt(f,y_test.reshape(y_test.shape[0], -1))\n",
    "f.close()\n",
    "\n",
    "f = open(main_path+\"models/v4/alexNet-v4/results/y_train.txt\", \"w\")\n",
    "np.savetxt(f,y_train.reshape(y_train.shape[0], -1))\n",
    "f.close()\n",
    "\n",
    "y_pred_onehot = model.predict(x_test, verbose=1)\n",
    "f = open(main_path+\"models/v4/alexNet-v4/results/y_preds_onehot.txt\", \"w\")\n",
    "np.savetxt(f,y_pred_onehot.reshape(y_pred_onehot.shape[0], -1))\n",
    "f.close()\n",
    "\n",
    "y_pred = np.argmax(y_pred_onehot, axis=2)\n",
    "f = open(main_path+\"models/v4/alexNet-v4/results/y_preds.txt\", \"w\")\n",
    "np.savetxt(f,y_pred.reshape(y_pred.shape[0], -1))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 1s 34ms/step - loss: 2.1899 - acc: 0.5776 - mse: 0.1247\n",
      "MODEL Metric names:  ['loss', 'acc', 'mse']\n",
      "loss: 2.1899328231811523\n",
      "accuracy: 0.5775847434997559\n",
      "mse: 0.12471990287303925\n",
      "HISTORY Keys:  dict_keys(['loss', 'acc', 'mse', 'val_loss', 'val_acc', 'val_mse'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Graficos\n",
    "'''\n",
    "#Matriz de confusion\n",
    "lab = [x for x in range(0,num_class)]\n",
    "matrix = multilabel_confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1), labels = lab)\n",
    "print(matrix)\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(matrix, annot=True, ax = ax); #annot=True to annotate cells\n",
    "plt.savefig(fname = \"/global/scratch/users/cpezov/AAPBO/models/v4/alexNet-v4/results/confMat.png\")\n",
    "'''\n",
    "#model.load_weights(\"/global/scratch/users/cpezov/AAPBO/models/v4/alexNet-v4/models/model.h5\") #cargalo de tu ruta\n",
    "score = model.evaluate(x_test, y_test,verbose=1)\n",
    "print(\"MODEL Metric names: \", model.metrics_names)\n",
    "print(\"loss:\", score[0])\n",
    "print(\"accuracy:\", score[1])\n",
    "print(\"mse:\", score[2])\n",
    "\n",
    "print(\"HISTORY Keys: \", alexNet_HISTORY.history.keys())\n",
    "plt.figure(0)\n",
    "plt.plot(alexNet_HISTORY.history['acc'])\n",
    "plt.plot(alexNet_HISTORY.history['val_acc'])\n",
    "plt.title(\"Training Accuracy vs Validation Accuracy\") \n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.savefig(main_path+'models/v4/alexNet-v4/results/acc_graph.png')\n",
    "\n",
    "# summarize history for loss\n",
    "plt.figure(1)\n",
    "plt.plot(alexNet_HISTORY.history['loss'])\n",
    "plt.plot(alexNet_HISTORY.history['val_loss'])\n",
    "plt.title(\"Training Loss vs Validation Loss\")\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig(main_path+'models/v4/alexNet-v4/results/loss_graph.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 62, 62, 96)        11712     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 62, 96)        384       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 30, 30, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 256)       614656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 30, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 384)       885120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 14, 14, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 256)       884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              37752832  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4000)              16388000  \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 500, 8)            0         \n",
      "=================================================================\n",
      "Total params: 74,651,616\n",
      "Trainable params: 74,648,864\n",
      "Non-trainable params: 2,752\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Load model\n",
    "\n",
    "# load json and create model\n",
    "json_file = open(main_path+\"models/v4/alexNet-v4/models/model.json\", 'r')\n",
    "model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(model_json)\n",
    "\n",
    "# load weights into new model\n",
    "model.load_weights(main_path+\"models/v4/alexNet-v4/models/model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "loss=\"categorical_crossentropy\"\n",
    "opt = keras.optimizers.Adam(learning_rate = 0.0001,epsilon=1e-08)\n",
    "\n",
    "model.compile(loss=loss, optimizer=opt, metrics=['acc', 'mse'])      \n",
    "model.summary() #ver resumen red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 3s 83ms/step\n",
      "34/34 [==============================] - 3s 84ms/step - loss: 2.1899 - acc: 0.5776 - mse: 0.1247\n",
      "MODEL Metric names:  ['loss', 'acc', 'mse']\n",
      "loss: 2.1899452209472656\n",
      "accuracy: 0.5776275396347046\n",
      "mse: 0.12471991032361984\n"
     ]
    }
   ],
   "source": [
    "#Verify model has same metrics\n",
    "\n",
    "y_pred_onehot = model.predict(x_test, verbose=1)\n",
    "y_pred = np.argmax(y_pred_onehot, axis=2)\n",
    "\n",
    "score = model.evaluate(x_test, y_test,verbose=1)\n",
    "print(\"MODEL Metric names: \", model.metrics_names)\n",
    "print(\"loss:\", score[0])\n",
    "print(\"accuracy:\", score[1])\n",
    "print(\"mse:\", score[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-05 18:04:40.635895\n"
     ]
    }
   ],
   "source": [
    "#Calcular tiempos de prediccin por cada par instancia-tiempo de test\n",
    "#(Correr esto se demora 1 hora aprox)\n",
    "\n",
    "now=datetime.datetime.now()\n",
    "print(now)\n",
    "\n",
    "l=int(len(y_pred))\n",
    "t_preds=np.empty(l*500) #Una prediccin da los resultados de todos los 500 timesteps\n",
    "\n",
    "#prediccion\n",
    "for i in range(len(x_test)):\n",
    "    #crear np.array de solo esa instancia-timestep\n",
    "    x_i = [x_test[i]]\n",
    "    x_i = np.array(x_i)\n",
    "    \n",
    "    #hacer prediccin y medir tiempo\n",
    "    start=time.time()\n",
    "    y_i = model.predict(x_i)\n",
    "    tiempo=time.time()-start\n",
    "    #Por cada instancia, guardar el mismo tiempo de prediccin para los 500 timesteps (para obtener el resultado de 1 timestep, el modelo debe obtener la prediccin para todos los timesteps, por lo que el tiempo que toma es el mismo para todos los timesteps)\n",
    "    for j in range(500): \n",
    "        t_preds[500*i+j]=tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10281348 0.10281348 0.10281348 ... 0.07706666 0.07706666 0.07706666]\n"
     ]
    }
   ],
   "source": [
    "#Guardar tiempos de prediccion\n",
    "\n",
    "print(t_preds)\n",
    "f = open(main_path+\"models/results-v4/pred_times/t_pred_alexNet-v4.txt\", \"w\")\n",
    "np.savetxt(f, t_preds, delimiter=\" \", fmt=\"%s\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-05 18:06:11.274843\n"
     ]
    }
   ],
   "source": [
    "now=datetime.datetime.now()\n",
    "print(now)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "cnn_GoogleNet",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python3.7 TF-2.3.0",
   "language": "python",
   "name": "python3.7-tf2.3.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
